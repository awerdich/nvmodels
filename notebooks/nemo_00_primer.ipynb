{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0d10a1-51e4-458a-8019-874a1f89f313",
   "metadata": {},
   "source": [
    "### NeMo Primer ###\n",
    "https://github.com/NVIDIA/NeMo/blob/main/tutorials/00_NeMo_Primer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0e8c1e-71e9-46ed-aa86-5715ec039dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package version: 0.0.1b0.post1.dev5+g11170d6\n",
      "PyTorch version: 2.3.0a0+ebedce2\n",
      "NeMo version:    2.0.0rc0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    " \n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# NeMo framework\n",
    "import nemo\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Appearance of the Notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import nvmodels\n",
    "\n",
    "print(f'Package version: {nvmodels.__version__}')\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'NeMo version:    {nemo.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452901f0-fe60-45e8-b8c0-b05210d8124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/data\n"
     ]
    }
   ],
   "source": [
    "# Directory for storing data\n",
    "print(os.environ.get('DATA_ROOT'))\n",
    "data_dir = os.path.join(os.environ.get('DATA_ROOT'), 'nemodata')\n",
    "model_dir = os.path.join(data_dir, 'nemomodel')\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a0391-9398-4b15-8e99-c50b315a098f",
   "metadata": {},
   "source": [
    "### NeMo Models in Collections ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41b5933-fd71-41bc-9bf2-5ff595b194bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASRModel',\n",
       " 'AudioToAudioModel',\n",
       " 'ClassificationInferConfig',\n",
       " 'ClusteringDiarizer',\n",
       " 'EncDecCTCModel',\n",
       " 'EncDecCTCModelBPE',\n",
       " 'EncDecClassificationModel',\n",
       " 'EncDecDiarLabelModel',\n",
       " 'EncDecFrameClassificationModel',\n",
       " 'EncDecHybridRNNTCTCBPEModel',\n",
       " 'EncDecHybridRNNTCTCModel',\n",
       " 'EncDecK2RnntSeqModel',\n",
       " 'EncDecK2RnntSeqModelBPE',\n",
       " 'EncDecK2SeqModel',\n",
       " 'EncDecK2SeqModelBPE',\n",
       " 'EncDecMultiTaskModel',\n",
       " 'EncDecRNNTBPEModel',\n",
       " 'EncDecRNNTModel',\n",
       " 'EncDecSpeakerLabelModel',\n",
       " 'EncDecTransfModelBPE',\n",
       " 'EncMaskDecAudioToAudioModel',\n",
       " 'NeuralDiarizer',\n",
       " 'PredictiveAudioToAudioModel',\n",
       " 'SLUIntentSlotBPEModel',\n",
       " 'ScoreBasedGenerativeAudioToAudioModel',\n",
       " 'SpeechEncDecSelfSupervisedModel',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'aed_multitask_models',\n",
       " 'asr_model',\n",
       " 'audio_to_audio_model',\n",
       " 'classification_models',\n",
       " 'clustering_diarizer',\n",
       " 'configs',\n",
       " 'ctc_bpe_models',\n",
       " 'ctc_models',\n",
       " 'enhancement_models',\n",
       " 'hybrid_rnnt_ctc_bpe_models',\n",
       " 'hybrid_rnnt_ctc_models',\n",
       " 'k2_sequence_models',\n",
       " 'label_models',\n",
       " 'msdd_models',\n",
       " 'rnnt_bpe_models',\n",
       " 'rnnt_models',\n",
       " 'slu_models',\n",
       " 'ssl_models',\n",
       " 'transformer_bpe_models']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Automatic Speech Recognition\n",
    "import nemo.collections.asr as nemo_asr\n",
    "asr_models = [model for model in dir(nemo_asr.models)]\n",
    "display(asr_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff98ad0-ffcf-40d0-9b66-7bbbcfbf0b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BERTLMModel',\n",
       " 'BertDPRModel',\n",
       " 'BertJointIRModel',\n",
       " 'DuplexDecoderModel',\n",
       " 'DuplexTaggerModel',\n",
       " 'DuplexTextNormalizationModel',\n",
       " 'EntityLinkingModel',\n",
       " 'GLUEModel',\n",
       " 'IntentSlotClassificationModel',\n",
       " 'MTEncDecModel',\n",
       " 'MegatronGPTPromptLearningModel',\n",
       " 'MultiLabelIntentSlotClassificationModel',\n",
       " 'PunctuationCapitalizationLexicalAudioModel',\n",
       " 'PunctuationCapitalizationModel',\n",
       " 'QAModel',\n",
       " 'SpellcheckingAsrCustomizationModel',\n",
       " 'Text2SparqlModel',\n",
       " 'TextClassificationModel',\n",
       " 'ThutmoseTaggerModel',\n",
       " 'TokenClassificationModel',\n",
       " 'TransformerLMModel',\n",
       " 'ZeroShotIntentModel',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'duplex_text_normalization',\n",
       " 'enc_dec_nlp_model',\n",
       " 'entity_linking',\n",
       " 'glue_benchmark',\n",
       " 'information_retrieval',\n",
       " 'intent_slot_classification',\n",
       " 'language_modeling',\n",
       " 'machine_translation',\n",
       " 'nlp_model',\n",
       " 'question_answering',\n",
       " 'spellchecking_asr_customization',\n",
       " 'text2sparql',\n",
       " 'text_classification',\n",
       " 'text_normalization_as_tagging',\n",
       " 'token_classification',\n",
       " 'zero_shot_intent_recognition']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NLP models\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "nlp_models = [model for model in dir(nemo_nlp.models)]\n",
    "display(nlp_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f15e7c4-0abb-475e-aaa4-2c2ea91575cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlignerModel',\n",
       " 'AudioCodecModel',\n",
       " 'FastPitchModel',\n",
       " 'GriffinLimModel',\n",
       " 'HifiGanModel',\n",
       " 'MelPsuedoInverseModel',\n",
       " 'MixerTTSModel',\n",
       " 'RadTTSModel',\n",
       " 'SpectrogramEnhancerModel',\n",
       " 'Tacotron2Model',\n",
       " 'TwoStagesModel',\n",
       " 'UnivNetModel',\n",
       " 'VitsModel',\n",
       " 'WaveGlowModel']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Text-to-speech TTS models\n",
    "import nemo.collections.tts as nemo_tts\n",
    "tts_models = [model for model in dir(nemo_tts.models) if model.endswith(\"Model\")]\n",
    "display(tts_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918bf26-7a49-4ad2-a6f9-89f1fae739c9",
   "metadata": {},
   "source": [
    "### The NeMo Model ###\n",
    "Let's dive deeper into what a NeMo model really is. There are many ways we can create these models - we can use the constructor and pass in a config, we can instantiate the model from a pre-trained checkpoint, or simply pass a pre-trained model name and instantiate a model directly from the cloud !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee110706-605e-4508-9ca0-8273a8ef75a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-05 20:17:33 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_512/versions/1.0.0rc1/files/stt_en_citrinet_512.nemo to /app/.cache/torch/NeMo/NeMo_2.0.0rc0/stt_en_citrinet_512/3262321355385bb7cf5a583146117d77/stt_en_citrinet_512.nemo\n",
      "[NeMo I 2024-08-05 20:17:35 common:815] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2024-08-05 20:17:37 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-05 20:17:37 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    \n",
      "[NeMo W 2024-08-05 20:17:37 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    \n",
      "[NeMo W 2024-08-05 20:17:37 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /home/smajumdar/PycharmProjects/nemo-eval/nemo_eval/librispeech/manifests/dev_other.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 12\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-05 20:17:37 features:305] PADDING: 16\n",
      "[NeMo I 2024-08-05 20:17:38 save_restore_connector:263] Model EncDecCTCModelBPE was successfully restored from /app/.cache/torch/NeMo/NeMo_2.0.0rc0/stt_en_citrinet_512/3262321355385bb7cf5a583146117d77/stt_en_citrinet_512.nemo.\n"
     ]
    }
   ],
   "source": [
    "# Let's try automatic speech recognition\n",
    "citrinet = nemo_asr.models.EncDecCTCModelBPE.from_pretrained('stt_en_citrinet_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf4dbd0-01c7-4fca-b89c-bd4fa3664b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params | Mode \n",
       "--------------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | train\n",
       "1 | encoder           | ConvASREncoder                    | 36.3 M | train\n",
       "2 | decoder           | ConvASRDecoder                    | 657 K  | train\n",
       "3 | loss              | CTCLoss                           | 0      | train\n",
       "4 | spec_augmentation | SpectrogramAugmentation           | 0      | train\n",
       "5 | wer               | WER                               | 0      | train\n",
       "--------------------------------------------------------------------------------\n",
       "37.0 M    Trainable params\n",
       "0         Non-trainable params\n",
       "37.0 M    Total params\n",
       "147.977   Total estimated model params size (MB)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(citrinet.summarize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28132dd8-f952-459d-8324-da575035f48e",
   "metadata": {},
   "source": [
    "### Model Configuration using OmegaConf ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "68e840df-cb7b-4b0e-871c-5cef52156d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sample_rate', 'train_ds', 'validation_ds', 'test_ds', 'model_defaults', 'tokenizer', 'preprocessor', 'spec_augment', 'encoder', 'decoder', 'optim', 'target', 'nemo_version', 'decoding'])\n"
     ]
    }
   ],
   "source": [
    "cfg = copy.deepcopy(citrinet.cfg)\n",
    "print(cfg.keys())\n",
    "# We can convert the configuration dictionary to a yaml file\n",
    "# print(OmegaConf.to_yaml(cfg))\n",
    "cfg_file = os.path.join(data_dir, 'citrinet.cfg')\n",
    "with open(cfg_file, 'w') as fl:\n",
    "    fl.write(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d22ddbb-7cbd-49c2-ae4a-f2bafb0f14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: novograd\n",
      "lr: 0.05\n",
      "betas:\n",
      "- 0.8\n",
      "- 0.25\n",
      "weight_decay: 0.001\n",
      "sched:\n",
      "  name: CosineAnnealing\n",
      "  warmup_steps: 1000\n",
      "  warmup_ratio: null\n",
      "  min_lr: 1.0e-09\n",
      "  last_epoch: -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's make a new copy of the configuration\n",
    "cfg = copy.deepcopy(citrinet.cfg)\n",
    "\n",
    "# OmegaConf will not allow adding new config items, we we temporarily disable this safeguard\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "\n",
    "# Let's see the old config\n",
    "print(OmegaConf.to_yaml(cfg.optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7f81f6e2-06d6-4b23-881b-ad4d741662bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Config: \n",
      "name: novograd\n",
      "lr: 0.05\n",
      "betas:\n",
      "- 0.8\n",
      "- 0.25\n",
      "weight_decay: 0.001\n",
      "sched:\n",
      "  name: CosineAnnealing\n",
      "  warmup_steps: 1006\n",
      "  min_lr: 1.0e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sched = {'name': 'CosineAnnealing', 'warmup_steps': 1006, 'min_lr': 1e-6}\n",
    "sched = OmegaConf.create(sched)  # Convert it into a DictConfig\n",
    "# Assign it to cfg.optim.sched namespace\n",
    "cfg.optim.sched = sched\n",
    "# Let's see the new optim config\n",
    "print(\"New Config: \")\n",
    "print(OmegaConf.to_yaml(cfg.optim))\n",
    "# Here, we restore the safeguards so no more additions can be made to the config\n",
    "OmegaConf.set_struct(cfg, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d041e8a-49ff-45d0-8b54-860f233299f7",
   "metadata": {},
   "source": [
    "### Changing the model configuration ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ae8bd4f2-f03f-49e3-b252-dd4795047149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sample_rate', 'train_ds', 'validation_ds', 'test_ds', 'model_defaults', 'tokenizer', 'preprocessor', 'spec_augment', 'encoder', 'decoder', 'optim', 'target', 'nemo_version', 'decoding'])\n",
      "\n",
      "{'_target_': 'nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor', 'sample_rate': 16000, 'normalize': 'per_feature', 'window_size': 0.025, 'window_stride': 0.01, 'window': 'hann', 'features': 80, 'n_fft': 512, 'frame_splicing': 1, 'dither': 1e-05, 'pad_to': 16, 'stft_conv': False}\n",
      "\n",
      "[NeMo I 2024-08-05 21:53:39 features:305] PADDING: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  | Name              | Type                              | Params | Mode \n",
       "--------------------------------------------------------------------------------\n",
       "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0      | train\n",
       "1 | encoder           | ConvASREncoder                    | 36.3 M | train\n",
       "2 | decoder           | ConvASRDecoder                    | 657 K  | train\n",
       "3 | loss              | CTCLoss                           | 0      | train\n",
       "4 | spec_augmentation | SpectrogramAugmentation           | 0      | train\n",
       "5 | wer               | WER                               | 0      | train\n",
       "--------------------------------------------------------------------------------\n",
       "37.0 M    Trainable params\n",
       "0         Non-trainable params\n",
       "37.0 M    Total params\n",
       "147.977   Total estimated model params size (MB)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a copy of the configuration of the model\n",
    "cfg = copy.deepcopy(citrinet.cfg)\n",
    "print(cfg.keys())\n",
    "\n",
    "# We want to change the preprocessor configuration\n",
    "new_preprocessor_cfg = copy.deepcopy(cfg.get('preprocessor'))\n",
    "print()\n",
    "# We can change this configuration\n",
    "pprint(new_preprocessor_cfg)\n",
    "\n",
    "# Save the new configuration\n",
    "print()\n",
    "new_preprocessor = citrinet.from_config_dict(new_preprocessor_cfg)\n",
    "# Replace the attribute\n",
    "dir(citrinet.preprocessor)\n",
    "citrinet.preprocessor = new_preprocessor\n",
    "\n",
    "display(citrinet.summarize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d775134-4ea4-45c8-903d-622bbe65c161",
   "metadata": {},
   "source": [
    "### Saving the updated model configuration ###\n",
    "Why do we want to do this? NeMo has many ways of saving and restoring its models, which we will discuss a bit later. All of them depend on having an updated config that defines the model in its entirety, so if we modify anything, we should also update the corresponding part of the config to safely save and restore models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "523b50c9-90d1-4539-933a-f4208e02e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the copy of the configuration\n",
    "cfg.preprocessor = new_preprocessor_cfg\n",
    "# Update the model config\n",
    "citrinet.cfg = cfg\n",
    "# Now, we need to save the citrinet model ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146bf050-645c-4c77-a577-1ad31633cbff",
   "metadata": {},
   "source": [
    "### Saving and restoring from .nemo files ###\n",
    "There are a few models which might require external dependencies to be packaged with them in order to restore them properly.\n",
    "\n",
    "One such example is an ASR model with an external BPE tokenizer. It is preferred if the model includes all of the components required to restore it, but a binary file for a tokenizer cannot be serialized into a PyTorch Lightning checkpoint.\n",
    "\n",
    "In such cases, we can use the save_to and restore_from method to package the entire model + its components (here, the tokenizer file(s)) into a tarfile. This can then be easily imported by the user and used to restore the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "25a0e3b9-c095-4374-afbe-7e236f48893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: novograd\n",
      "lr: 0.05\n",
      "betas:\n",
      "- 0.8\n",
      "- 0.25\n",
      "weight_decay: 0.001\n",
      "sched:\n",
      "  name: CosineAnnealing\n",
      "  warmup_steps: 1000\n",
      "  warmup_ratio: null\n",
      "  min_lr: 1.0e-09\n",
      "  last_epoch: -1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the current optimizer\n",
    "print(OmegaConf.to_yaml(citrinet.cfg.optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "77c8449f-bb4e-4171-8506-5441c27018e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-05 22:45:09 modelPT:652] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-05 22:45:09 modelPT:770] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.8, 0.25]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.05\n",
      "        weight_decay: 0.001\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-05 22:45:09 lr_scheduler:903] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Novograd (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: [0.8, 0.25]\n",
       "     eps: 1e-08\n",
       "     grad_averaging: False\n",
       "     lr: 0.05\n",
       "     weight_decay: 0.001\n",
       " ),\n",
       " None)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's update the configuration\n",
    "citrinet.setup_optimization(cfg.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4f4e0135-7220-4ce6-94f6-b391c44f8700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "omegaconf.dictconfig.DictConfig"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-05 22:53:50 modelPT:652] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-05 22:53:50 modelPT:770] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.8, 0.25]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.05\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2024-08-05 22:53:50 lr_scheduler:923] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7e7c14158df0>\" \n",
      "    will be used during training (effective maximum steps = 100) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 1006\n",
      "    min_lr: 1.0e-06\n",
      "    max_steps: 100\n",
      "    )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Novograd (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: [0.8, 0.25]\n",
       "     eps: 1e-08\n",
       "     grad_averaging: False\n",
       "     initial_lr: 0.05\n",
       "     lr: 4.965243296921549e-05\n",
       "     weight_decay: 0.001\n",
       " ),\n",
       " {'scheduler': <nemo.core.optim.lr_scheduler.CosineAnnealing at 0x7e7c14158df0>,\n",
       "  'interval': 'step',\n",
       "  'frequency': 1,\n",
       "  'monitor': 'loss',\n",
       "  'reduce_on_plateau': False})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(type(cfg))\n",
    "OmegaConf.set_struct(cfg.optim.sched, value=True)\n",
    "# Now we can add a new key, value pair\n",
    "# Let's also change the scheduler\n",
    "sched = {'name': 'CosineAnnealing', 'warmup_steps': 1006, 'min_lr': 1e-6, 'max_steps': 100}\n",
    "sched = OmegaConf.create(sched)  # Convert it into a DictConfig\n",
    "# Assign it to cfg.optim.sched namespace\n",
    "cfg.optim.sched = sched\n",
    "OmegaConf.set_struct(cfg.optim.sched, value=True)\n",
    "# Now let's update the config and try again\n",
    "citrinet.setup_optimization(cfg.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "261c107e-7bac-4152-9607-03f46ecd9ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'CosineAnnealing', 'warmup_steps': 1006, 'min_lr': 1e-06, 'max_steps': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at the changes\n",
    "cfg = copy.deepcopy(citrinet.cfg)\n",
    "display(cfg.get('optim').get('sched'))\n",
    "citrinet.cfg.optim = cfg.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "96e34664-c17e-402c-94e5-f6209d68d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/data/nemodata/nemomodel/citrinet_512.nemo\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "# citrinet = nemo_asr.models.EncDecCTCModelBPE.from_pretrained('stt_en_citrinet_512')\n",
    "model_name = 'citrinet_512.nemo'\n",
    "model_file = os.path.join(model_dir, model_name)\n",
    "print(model_file)\n",
    "citrinet.save_to(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e53c3fd-c710-41e5-a2b9-9bb7dfeedd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-05 22:59:11 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-08-05 22:59:11 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    \n",
      "[NeMo W 2024-08-05 22:59:11 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    \n",
      "[NeMo W 2024-08-05 22:59:11 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /home/smajumdar/PycharmProjects/nemo-eval/nemo_eval/librispeech/manifests/dev_other.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 12\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-08-05 22:59:11 features:305] PADDING: 16\n",
      "[NeMo I 2024-08-05 22:59:13 save_restore_connector:263] Model EncDecCTCModelBPE was successfully restored from /app/data/nemodata/nemomodel/citrinet_512.nemo.\n"
     ]
    }
   ],
   "source": [
    "# Restore the model \n",
    "model_name = 'citrinet_512.nemo'\n",
    "model_file = os.path.join(model_dir, model_name)\n",
    "\n",
    "new_cn = nemo_asr.models.EncDecCTCModelBPE.restore_from(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ded5af8-b977-4afe-8349-fd7fb9f64bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'CosineAnnealing', 'warmup_steps': 1006, 'min_lr': 1e-06, 'max_steps': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_cfg = copy.deepcopy(new_cn.cfg)\n",
    "display(new_cfg.get('optim').get('sched'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
